{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b36cb2d-4655-4b89-866e-f7ec7a9f586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from geopy.geocoders import GoogleV3\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQuotaExceeded\n",
    "import time\n",
    "import re\n",
    "from geopy.geocoders import GoogleV3\n",
    "import time\n",
    "import requests\n",
    "from fuzzywuzzy import process\n",
    "import logging\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2765871-256c-459a-a7db-2b9ae944eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='geocoding.log', level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f199379e-f576-46f8-9bf6-e4bfb9299a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/Users/gayathri/Documents/GPE_Analysis'\n",
    "output_folder = '/Users/gayathri/Documents/GPE_Analysis'\n",
    "# Replace 'your_api_key' with your actual Google Geocoding API key\n",
    "api_key = 'AIzaSyBJ8P42fvaYv5pmqNdEqYEOJPENnm7eND0'\n",
    "# Initialize the Google Geocoding client\n",
    "geolocator = GoogleV3(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "137fd08b-fd0d-4eef-a4f4-6a53afbc843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_based_location(csv_data, file):\n",
    "    # Group the data based on 'gpe_latitude' and 'gpe_longitude' and create a new column 'group_ID'\n",
    "    csv_data['group_ID'] = csv_data.groupby(['gpe_latitude', 'gpe_longitude']).ngroup()\n",
    "    # Sort the DataFrame based on the 'group_ID' column\n",
    "    csv_data.sort_values(by='group_ID', inplace=True)\n",
    "    # Reset the index after sorting (optional)\n",
    "    csv_data.reset_index(drop=True, inplace=True)\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    save_file = \"grouped_data_\" + file + \".csv\"  # Adjust the naming as needed\n",
    "    output_file_path = os.path.join(output_folder, save_file)\n",
    "    csv_data.to_csv(output_file_path, index=False)\n",
    "    print(\"file saved after grouping \", save_file)\n",
    "    return csv_data\n",
    "\n",
    "def find_most_relevant_gpe(group_df):\n",
    "    gpe_variations = group_df['gpe'].tolist()\n",
    "    # Find the best match for the first 'gpe' name in the group\n",
    "    best_match, _ = process.extractOne(group_df['gpe'].iloc[0], gpe_variations, scorer=fuzz.ratio)\n",
    "    # Assign the best match to all rows in the group\n",
    "    group_df['gpe_new'] = best_match  # Update the 'gpe_new' column in the group_df\n",
    "    return group_df  # Return the updated group_df\n",
    "\n",
    "def format_gpe(csv_data, file):\n",
    "    # To remove 's(apostrophe s) from the GPE name => Formatting the data step 1.\n",
    "    csv_data['gpe'] = csv_data['gpe'].apply(lambda x: re.sub(r\"'s$\", \"\", x))\n",
    "    csv_data['gpe'] = csv_data['gpe'].apply(lambda x: x.title())\n",
    "    print(\"done with setting gpename\")\n",
    "    # Use apply to call find_most_relevant_gpe on each group\n",
    "    csv_data = csv_data.groupby('group_ID').apply(find_most_relevant_gpe).reset_index(level=0, drop=True)\n",
    "    print(\"done with formatting\")\n",
    "    save_file = \"formatted_data_\" + file + \".csv\"  # Adjust the naming as needed\n",
    "    output_file_path = os.path.join(output_folder, save_file)\n",
    "    csv_data.to_csv(output_file_path, index=False)\n",
    "    print(\"File saved after formatting: \", save_file)\n",
    "    return csv_data\n",
    "\n",
    "def sum_and_no_duplicates(csv_data,file):\n",
    "    csv_data['gpe_sum'] = csv_data.groupby(['gpe_new', 'group_ID'])['gpe_occurrences'].transform('sum')\n",
    "    csv_data = csv_data.drop_duplicates(subset=['gpe_new'], keep='first')\n",
    "    save_file = \"no_duplicates_\" + file + \".csv\" # Adjust the naming as needed\n",
    "    output_file_path = os.path.join(output_folder, save_file)\n",
    "    csv_data.to_csv(output_file_path, index=False)\n",
    "    print(\"file saved after sum_and_no_duplicates \", save_file)\n",
    "    return csv_data\n",
    "\n",
    "def is_location_with_spacy(word):\n",
    "    doc = nlp(word)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def validate_gpe_with_spacy(csv_data, file):\n",
    "    # Create a new column 'Is_Valid' in the DataFrame to store validation results\n",
    "    csv_data['Is_Valid'] = csv_data['gpe_new'].apply(lambda x: is_location_with_spacy(x))\n",
    "    # Convert 'Is_Valid' to 1 for valid and 0 for invalid\n",
    "    csv_data['Is_Valid'] = csv_data['Is_Valid'].astype(int)\n",
    "    save_file = \"valid_gpe_\" + file + \".csv\"\n",
    "    output_file_path = os.path.join(output_folder, save_file)\n",
    "    csv_data.to_csv(output_file_path, index=False)\n",
    "    print(\"File saved after validate_gpe: \", save_file)\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce250964-3e88-4f70-b24c-fcb3146cb937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved after grouping  grouped_data_6abc.csv\n",
      "done with setting gpename\n",
      "done with formatting\n",
      "File saved after formatting:  formatted_data_6abc.csv\n",
      "file saved after sum_and_no_duplicates  no_duplicates_6abc.csv\n",
      "File saved after validate_gpe:  valid_gpe_6abc.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "# folder_path = '/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/GPE_intra_domain_cleaned'\n",
    "    \n",
    "# Iterate through each CSV file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read the CSV file\n",
    "        csv_data = pd.read_csv(file_path)\n",
    "        parts = filename.split('_')\n",
    "        file = parts[-1].split('.')[0]\n",
    "        invalid_places = \"invalid_places\"+file\n",
    "        csv_data = grouping_based_location(csv_data,file)\n",
    "        csv_data = format_gpe(csv_data,file)\n",
    "        csv_data = sum_and_no_duplicates(csv_data,file)\n",
    "        csv_data = validate_gpe_with_spacy(csv_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a146d-17db-4f07-a210-fc0014fe25a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
