{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b892865-1185-4dbc-94d8-2bf2bc7812bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gayathri/myenv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from shapely import wkt\n",
    "import re\n",
    "import spacy\n",
    "import csv\n",
    "import random\n",
    "from spacy.lang.en.examples import sentences \n",
    "from geopy.distance import great_circle\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ff73a4-5fe8-4174-91b1-4bdf7cb1a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(csv_file, output_folder):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    grouped = data.groupby('bart_label')\n",
    "    for bart_label, group in grouped:\n",
    "        filename = os.path.join(output_folder, f'{os.path.splitext(os.path.basename(csv_file))[0]}_{bart_label.lower()}.csv')  \n",
    "        group.to_csv(filename, index=False)\n",
    "\n",
    "folder_path = '/Users/gayathri/Desktop/Domain_Label'\n",
    "output_folder = '/Users/gayathri/Desktop/Domain_Label'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(folder_path, file_name)\n",
    "        process_csv(csv_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb43608-930a-41ed-9d1a-16344b8a702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920thejersey.csv: 1 files\n",
      "6abc: 10 files\n",
      "943thepoint: 10 files\n",
      "1057thehawk: 9 files\n",
      "hellenicnews: 5 files\n",
      "dailyvoice: 9 files\n",
      "literock969: 10 files\n",
      "baristanet: 8 files\n",
      "943thepoint.csv: 1 files\n",
      ".DS: 1 files\n",
      "dailyvoice.csv: 1 files\n",
      "am970theanswer: 8 files\n",
      "forward.csv: 1 files\n",
      "920thejersey: 7 files\n",
      "forward: 6 files\n",
      "6abc.csv: 1 files\n",
      "hellenicnews.csv: 1 files\n",
      "baristanet.csv: 1 files\n",
      "literock969.csv: 1 files\n",
      "am970theanswer.csv: 1 files\n",
      "1057thehawk.csv: 1 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_by_prefix(folder_path):\n",
    "    file_counts = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        prefix = file_name.split('_')[0]\n",
    "        file_counts[prefix] = file_counts.get(prefix, 0) + 1\n",
    "    for prefix, count in file_counts.items():\n",
    "        print(f\"{prefix}: {count} files\")\n",
    "\n",
    "folder_path = '/Users/gayathri/Desktop/Domain_Label'\n",
    "\n",
    "count_files_by_prefix(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd89d1a-4a93-4aff-898d-191526b43777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 920thejersey.csv, Total unique bart_labels: 7\n",
      "Unique bart_labels:\n",
      "Business\n",
      "World\n",
      "Sports\n",
      "Automobile\n",
      "Environment\n",
      "Crime\n",
      "Health\n",
      "\n",
      "File: 943thepoint.csv, Total unique bart_labels: 10\n",
      "Unique bart_labels:\n",
      "World\n",
      "Business\n",
      "Crime\n",
      "Automobile\n",
      "Environment\n",
      "Health\n",
      "Miscellaneous\n",
      "Sports\n",
      "Politics\n",
      "Education\n",
      "\n",
      "File: dailyvoice.csv, Total unique bart_labels: 9\n",
      "Unique bart_labels:\n",
      "Business\n",
      "Automobile\n",
      "Crime\n",
      "World\n",
      "Politics\n",
      "Health\n",
      "Environment\n",
      "Sports\n",
      "Education\n",
      "\n",
      "File: forward.csv, Total unique bart_labels: 6\n",
      "Unique bart_labels:\n",
      "World\n",
      "Business\n",
      "Health\n",
      "Politics\n",
      "Crime\n",
      "Sports\n",
      "\n",
      "File: 6abc.csv, Total unique bart_labels: 10\n",
      "Unique bart_labels:\n",
      "World\n",
      "Sports\n",
      "Crime\n",
      "Miscellaneous\n",
      "Health\n",
      "Business\n",
      "Environment\n",
      "Politics\n",
      "Automobile\n",
      "Education\n",
      "\n",
      "File: hellenicnews.csv, Total unique bart_labels: 5\n",
      "Unique bart_labels:\n",
      "World\n",
      "Sports\n",
      "Business\n",
      "Politics\n",
      "Health\n",
      "\n",
      "File: baristanet.csv, Total unique bart_labels: 8\n",
      "Unique bart_labels:\n",
      "World\n",
      "Politics\n",
      "Business\n",
      "Education\n",
      "Sports\n",
      "Health\n",
      "Environment\n",
      "Crime\n",
      "\n",
      "File: literock969.csv, Total unique bart_labels: 10\n",
      "Unique bart_labels:\n",
      "World\n",
      "Health\n",
      "Business\n",
      "Crime\n",
      "Education\n",
      "Environment\n",
      "Automobile\n",
      "Sports\n",
      "Politics\n",
      "Miscellaneous\n",
      "\n",
      "File: am970theanswer.csv, Total unique bart_labels: 8\n",
      "Unique bart_labels:\n",
      "Crime\n",
      "World\n",
      "Politics\n",
      "Sports\n",
      "Education\n",
      "Environment\n",
      "Business\n",
      "Health\n",
      "\n",
      "File: 1057thehawk.csv, Total unique bart_labels: 9\n",
      "Unique bart_labels:\n",
      "Sports\n",
      "Business\n",
      "Education\n",
      "World\n",
      "Health\n",
      "Environment\n",
      "Crime\n",
      "Automobile\n",
      "Politics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###This is a verication code to check if we could successfully generate the sub bart_label files #####\n",
    "def print_unique_bart_labels(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            csv_file = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(csv_file)\n",
    "            unique_labels = df['bart_label'].unique()\n",
    "            print(f\"File: {file_name}, Total unique bart_labels: {len(unique_labels)}\")\n",
    "            print(\"Unique bart_labels:\")\n",
    "            for label in unique_labels:\n",
    "                print(label)\n",
    "            print()  \n",
    "\n",
    "folder_path = '/Users/gayathri/Desktop/Domain_Label/main_data'\n",
    "\n",
    "print_unique_bart_labels(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fcd2d0-a53b-4f97-9692-73a1f91042af",
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is to put all the files of same domain to one folder###\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_csv_files(folder_path):\n",
    "    # Create a dictionary to store folder paths for each prefix\n",
    "    folder_paths = {}\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            prefix = file_name.split('_')[0]\n",
    "            \n",
    "            if prefix not in folder_paths:\n",
    "                folder_paths[prefix] = os.path.join(folder_path, prefix)\n",
    "                folder_path_suffix = 0\n",
    "                while os.path.exists(folder_paths[prefix]):\n",
    "                    folder_path_suffix += 1\n",
    "                    folder_paths[prefix] = os.path.join(folder_path, f\"{prefix}_{folder_path_suffix}\")\n",
    "                os.makedirs(folder_paths[prefix], exist_ok=True)\n",
    "            \n",
    "            src_file = os.path.join(folder_path, file_name)\n",
    "            dst_file = os.path.join(folder_paths[prefix], file_name)\n",
    "            shutil.move(src_file, dst_file)\n",
    "\n",
    "folder_path = '/Users/gayathri/Desktop/Domain_Label'\n",
    "\n",
    "organize_csv_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113b59df-7f79-4acc-a1a2-1bd01a1dad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Now, let's generate the pinpoint map for all the sub files of multiple domains###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5ebecc-3e79-48eb-aca2-7358bf35b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(csv_file, color):\n",
    "    df = pd.read_csv(csv_file)    \n",
    "    df['gpe_sum_log'] = np.log(df['gpe_sum']) / np.log(np.e)  # Calculate gpe_sum_log\n",
    "    map_zoom = 10\n",
    "    max_occurrences_row = df.loc[df['gpe_sum'].idxmax()]\n",
    "    highest_occurrence = [highest_occurrences_latitude, highest_occurrences_longitude]\n",
    "    mymap = folium.Map(location=highest_occurrence, zoom_start=map_zoom)\n",
    "\n",
    "    max_count = df[\"gpe_sum_log\"].max()\n",
    "\n",
    "    def get_marker_size(log_count):\n",
    "        scale_factor = 10  \n",
    "        return 5 + (log_count / max_count) * scale_factor\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        location = row[\"gpe\"]\n",
    "        latitude = row[\"gpe_latitude\"]\n",
    "        longitude = row[\"gpe_longitude\"]\n",
    "        count = row[\"gpe_sum\"]\n",
    "        log_count = row[\"gpe_sum_log\"]\n",
    "        popup_text = f\"Location: {location}\\nCount: {count}\"\n",
    "        marker_size = get_marker_size(log_count)\n",
    "        folium.CircleMarker(\n",
    "            [latitude, longitude],\n",
    "            popup=popup_text,\n",
    "            radius=marker_size,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color\n",
    "        ).add_to(mymap)\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(csv_file))[0] + \".html\"\n",
    "    output_file = os.path.join(os.path.dirname(csv_file), filename)\n",
    "    mymap.save(output_file)\n",
    "\n",
    "folder_path = \"/Users/gayathri/Desktop/Domain_Label/literock969\"\n",
    "\n",
    "color_palette = ['#e6194b', '#3cb44b', '#194fff', '#873ec7', '#de6109', \n",
    "                 '#911eb4', '#f7890a', '#f032e6', '#bcf60c', '#e62e2e']\n",
    "\n",
    "color_index = 0\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(folder_path, filename)\n",
    "        color = color_palette[color_index % len(color_palette)]\n",
    "        process_csv_file(csv_file, color)\n",
    "        color_index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
