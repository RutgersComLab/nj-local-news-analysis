{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2b6ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\program files\\python37\\lib\\site-packages (0.25.3)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python37\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Collecting folium\n",
      "  Downloading folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from folium) (3.1.2)\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python37\\lib\\site-packages (0.25.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\program files\\python37\\lib\\site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python37\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python37\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\program files\\python37\\lib\\site-packages (from pandas) (2019.3)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.16.1-py2.py3-none-any.whl (15.6 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from plotly) (23.1)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python37\\lib\\site-packages (0.25.3)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python37\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from seaborn) (4.7.1)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.0.1-cp37-cp37m-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python37\\lib\\site-packages (1.17.2)\n",
      "Collecting branca>=0.6.0\n",
      "  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: six in c:\\program files\\python37\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.9.4.post1-cp37-cp37m-win_amd64.whl (22.7 MB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from fiona>=1.8->geopandas) (6.7.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from fiona>=1.8->geopandas) (23.1.0)\n",
      "Requirement already satisfied: six in c:\\program files\\python37\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from fiona>=1.8->geopandas) (6.7.0)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Collecting click~=8.0\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from fiona>=1.8->geopandas) (6.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from click~=8.0->fiona>=1.8->geopandas) (0.4.6)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->fiona>=1.8->geopandas) (3.15.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from seaborn) (4.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-win_amd64.whl (6.2 MB)\n",
      "Requirement already satisfied: six in c:\\program files\\python37\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alter\\appdata\\roaming\\python\\python37\\site-packages (from requests->folium) (3.4)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.2.0-cp37-cp37m-win_amd64.whl (94 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "Installing collected packages: click, urllib3, cligj, click-plugins, charset-normalizer, certifi, tenacity, shapely, requests, pyproj, fiona, branca, seaborn, plotly, geopandas, folium\n",
      "Successfully installed branca-0.6.0 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.7 click-plugins-1.1.1 cligj-0.7.2 fiona-1.9.4.post1 folium-0.14.0 geopandas-0.10.2 plotly-5.16.1 pyproj-3.2.1 requests-2.31.0 seaborn-0.12.2 shapely-2.0.1 tenacity-8.2.3 urllib3-2.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\alter\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pyproj.exe is installed in 'C:\\Users\\alter\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fio.exe is installed in 'C:\\Users\\alter\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 20.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4120\\2028555610.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install pandas geopandas folium shapely plotly seaborn matplotlib numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python -m spacy download en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "!pip install pandas geopandas folium shapely plotly seaborn matplotlib numpy\n",
    "\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from shapely import wkt\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "from spacy.lang.en.examples import sentences \n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from difflib import SequenceMatcher\n",
    "from geopy.distance import great_circle, GeocoderTimedOut, GeocoderServiceError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4f32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a30465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name of outlet', 'Outlet URL'], dtype='object')\n",
      "(656, 2)\n"
     ]
    }
   ],
   "source": [
    "#Reading the grouped data from the previous one\n",
    "df = pd.read_csv('/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/results/urls_658.csv')\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38533cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"name\", \"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4cc68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hostname\"] = df[\"url\"].apply(lambda x: urlparse(x).hostname)\n",
    "df[\"path\"] = df[\"url\"].apply(lambda x: urlparse(x).path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4f015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostname</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>communitynews.org</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dailyvoice.com</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>hudsonreporter.com</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>magic983.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>medium.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mybeachradio.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>newjersey.news12.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>patch.com</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>rennamedia.com</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>thepressgroup.net</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>thesunpapers.com</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>trentonmonitor.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>www.centraljersey.com</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>www.jerseyshoreonline.com</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>www.mainlinemedianews.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>www.mycentraljersey.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>www.mypaperonline.com</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>www.newjerseyhills.com</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>www.nj.com</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>www.northjersey.com</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>www.pressofatlanticcity.com</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>www.tapinto.net</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>www.univision.com</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>www.wnyc.org</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hostname  count\n",
       "31             communitynews.org     10\n",
       "34                dailyvoice.com     22\n",
       "54            hudsonreporter.com      3\n",
       "62                  magic983.com      2\n",
       "65                    medium.com      2\n",
       "70              mybeachradio.com      2\n",
       "73          newjersey.news12.com      2\n",
       "88                     patch.com    101\n",
       "99                rennamedia.com     20\n",
       "124            thepressgroup.net      2\n",
       "128             thesunpapers.com      8\n",
       "131           trentonmonitor.com      2\n",
       "173        www.centraljersey.com     21\n",
       "186             www.facebook.com      2\n",
       "206    www.jerseyshoreonline.com      4\n",
       "219    www.mainlinemedianews.com      2\n",
       "229      www.mycentraljersey.com      2\n",
       "230        www.mypaperonline.com     16\n",
       "236       www.newjerseyhills.com     14\n",
       "238                   www.nj.com      6\n",
       "247          www.northjersey.com      3\n",
       "262  www.pressofatlanticcity.com     10\n",
       "286              www.tapinto.net     69\n",
       "319            www.univision.com      2\n",
       "337                 www.wnyc.org      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['hostname'])['url'].size().to_frame(name = 'count').reset_index()\n",
    "df1.loc[df1['count']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a50b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the result in descending order based on the 'url' count\n",
    "df1 = df1.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df1.to_csv('hostname_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d15aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "# Count values greater than 1\n",
    "count_greater_than_1 = len(df1[df1['count'] > 1])\n",
    "\n",
    "# Count values equal to 1\n",
    "count_equal_to_1 = len(df1[df1['count'] == 1])\n",
    "print(count_greater_than_1)\n",
    "print(count_equal_to_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c95e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'url', 'comments'], dtype='object')\n",
      "(332, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "distinct = pd.read_excel('/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/results/urls.xlsx', sheet_name=0, engine='openpyxl')\n",
    "distinct = distinct.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "# Now, 'distinct' contains the data from the first sheet of the Excel file\n",
    "print(distinct.columns)\n",
    "print(distinct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a8b05a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'url', 'comments'], dtype='object')\n",
      "(317, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "same = pd.read_excel(r'C:\\Users\\alter\\Box\\Local News Data\\results\\urls.xlsx', sheet_name=1, engine='openpyxl')\n",
    "same = same.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "# Now, 'distinct' contains the data from the first sheet of the Excel file\n",
    "print(same.columns)\n",
    "print(same.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ea2f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'unique_articles_count', 'crawl_count'], dtype='object')\n",
      "(434, 3)\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv('\\\\Users\\\\alter\\\\Box\\\\Local News Data\\\\results\\\\original_metadata.csv')\n",
    "print(original.columns)\n",
    "print(original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7261374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of unique_articles_count: 514620\n",
      "Unique number of URL values: 434\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of unique_articles_count\n",
    "sum_unique_articles = original['unique_articles_count'].sum()\n",
    "print(f\"Sum of unique_articles_count: {sum_unique_articles}\")\n",
    "\n",
    "# Calculate the unique number of URL values\n",
    "unique_urls_count = original['url'].nunique()\n",
    "print(f\"Unique number of URL values: {unique_urls_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
