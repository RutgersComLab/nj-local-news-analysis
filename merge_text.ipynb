{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "446979eb-e9e9-46c3-b007-6c8a0e1930c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging complete. Merged file saved as 'merged_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "###This merge is from the initial set of cleaned_data => categorized_data \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = '/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/data/categorized_data'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each CSV file and merge its data into the main DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('all_domain_text.csv', index=False)\n",
    "\n",
    "print(\"Merging complete. Merged file saved as 'merged_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2448aedd-93e2-4a7d-a410-34b958982876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"all_domain_text.csv\").rename(columns={\"article_url\": \"news_url\"}).to_csv(\"all_domain_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5458b925-5280-4b67-b0cf-c75fd359f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here we are trying to merge the data from categorised_data to each domain level based on the column news_url. This gives us the bart_label and the data added to our analysed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8673f4f7-7a2d-4e01-a060-9e14b695cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to no_duplicates_brick.shorebeat.csv\n",
      "Merged data saved to no_duplicates_montynews.csv\n",
      "Merged data saved to no_duplicates_njjewishnews.timesofisrael.csv\n",
      "Merged data saved to no_duplicates_wpgtalkradio.csv\n",
      "Merged data saved to no_duplicates_www.recordonline.csv\n",
      "Merged data saved to no_duplicates_www.951wayv.csv\n",
      "Merged data saved to no_duplicates_wsou.csv\n",
      "Merged data saved to no_duplicates_dailyvoice.csv\n",
      "Merged data saved to no_duplicates_njrevolutionradio.csv\n",
      "Merged data saved to no_duplicates_www.roi-nj.csv\n",
      "Merged data saved to no_duplicates_divyabhaskar.csv\n",
      "Merged data saved to no_duplicates_literock969.csv\n",
      "Merged data saved to no_duplicates_cccvoice.wordpress.csv\n",
      "Merged data saved to no_duplicates_www.posteaglenewspaper.csv\n",
      "Merged data saved to no_duplicates_www.njpen.csv\n",
      "Merged data saved to no_duplicates_am970theanswer.csv\n",
      "Merged data saved to no_duplicates_civicstory.csv\n",
      "Merged data saved to no_duplicates_phl17.csv\n",
      "Merged data saved to no_duplicates_philadelphia.cbslocal.csv\n",
      "Merged data saved to no_duplicates_www.telemundo47.csv\n",
      "Merged data saved to no_duplicates_www.newsindiatimes.csv\n",
      "Merged data saved to no_duplicates_www.koreadailyus.csv\n",
      "Merged data saved to no_duplicates_www.stocktonargo.csv\n",
      "Merged data saved to no_duplicates_wlvt.csv\n",
      "Merged data saved to no_duplicates_newjerseybuzz.csv\n",
      "Merged data saved to no_duplicates_newtownpress.csv\n",
      "Merged data saved to no_duplicates_www.jerseyvoices.csv\n",
      "Merged data saved to no_duplicates_www.hobokenhorse.csv\n",
      "Merged data saved to no_duplicates_hellenicnews.csv\n",
      "Merged data saved to no_duplicates_1057thehawk.csv\n",
      "Merged data saved to no_duplicates_thepositivecommunity.csv\n",
      "Merged data saved to no_duplicates_thecoaster.csv\n",
      "Merged data saved to no_duplicates_tcnjsignal.csv\n",
      "Merged data saved to no_duplicates_www.law.csv\n",
      "Merged data saved to no_duplicates_brigantinenow.csv\n",
      "Merged data saved to no_duplicates_anointedonline.csv\n",
      "Merged data saved to no_duplicates_pinebarrenstribune.csv\n",
      "Merged data saved to no_duplicates_www.hammontongazette.csv\n",
      "Merged data saved to no_duplicates_savejersey.csv\n",
      "Merged data saved to no_duplicates_rcan.csv\n",
      "Merged data saved to no_duplicates_www.my9nj.csv\n",
      "Merged data saved to no_duplicates_forward.csv\n",
      "Merged data saved to no_duplicates_pocono967.csv\n",
      "Merged data saved to no_duplicates_wbjb.csv\n",
      "Merged data saved to no_duplicates_theobserver.csv\n",
      "Merged data saved to no_duplicates_www.princetonmagazine.csv\n",
      "Merged data saved to no_duplicates_radio.csv\n",
      "Merged data saved to no_duplicates_www.theridernews.csv\n",
      "Merged data saved to no_duplicates_mycommunitysource.csv\n",
      "Merged data saved to no_duplicates_fduequinox.wordpress.csv\n",
      "Merged data saved to no_duplicates_medium.csv\n",
      "Merged data saved to no_duplicates_thepakistaninewspaper.csv\n",
      "Merged data saved to no_duplicates_wliw.csv\n",
      "Merged data saved to no_duplicates_wwfm.csv\n",
      "Merged data saved to no_duplicates_sojo1049.csv\n",
      "Merged data saved to no_duplicates_www.northjersey.csv\n",
      "Merged data saved to no_duplicates_6abc.csv\n",
      "Merged data saved to no_duplicates_www.mycentraljersey.csv\n",
      "Merged data saved to no_duplicates_eccobserverdotcom.wordpress.csv\n",
      "Merged data saved to no_duplicates_www.townshipjournal.csv\n",
      "Merged data saved to no_duplicates_www.the-gazette-newspaper.csv\n",
      "Merged data saved to no_duplicates_www.1077thebronc.csv\n",
      "Merged data saved to no_duplicates_www.rahwayrising.csv\n",
      "Merged data saved to no_duplicates_nepszava.csv\n",
      "Merged data saved to no_duplicates_www.lavocedinewyork.csv\n",
      "Merged data saved to no_duplicates_www.indiaabroad.csv\n",
      "Merged data saved to no_duplicates_www.towntopics.csv\n",
      "Merged data saved to no_duplicates_rennamedia.csv\n",
      "Merged data saved to no_duplicates_www.tygodnikplus.csv\n",
      "Merged data saved to no_duplicates_www.shorelocalnews.csv\n",
      "Merged data saved to no_duplicates_www.visionsnewspaper.csv\n",
      "Merged data saved to no_duplicates_www.tristatevoice.csv\n",
      "Merged data saved to no_duplicates_baristanet.csv\n",
      "Merged data saved to no_duplicates_www.theyeshivaworld.csv\n",
      "Merged data saved to no_duplicates_wputimes.wordpress.csv\n",
      "Merged data saved to no_duplicates_newjerseyglobe.csv\n",
      "Merged data saved to no_duplicates_www.classicoldieswmid.csv\n",
      "Merged data saved to no_duplicates_www.pressofatlanticcity.csv\n",
      "Merged data saved to no_duplicates_www.jerseyshoreonline.csv\n",
      "Merged data saved to no_duplicates_newstalk990.csv\n",
      "Merged data saved to no_duplicates_latribunanj.csv\n",
      "Merged data saved to no_duplicates_www.wvlt.csv\n",
      "Merged data saved to no_duplicates_njbmagazine.csv\n",
      "Merged data saved to no_duplicates_920thejersey.csv\n",
      "Merged data saved to no_duplicates_wurdradio.csv\n",
      "Merged data saved to no_duplicates_www.urbanagendamagazine.csv\n",
      "Merged data saved to no_duplicates_www.dirt-mag.csv\n",
      "Merged data saved to no_duplicates_www.phillyvoice.csv\n",
      "Merged data saved to no_duplicates_wnyc.csv\n",
      "Merged data saved to no_duplicates_www.thedrewacorn.csv\n",
      "Merged data saved to no_duplicates_thenjsentinel.csv\n",
      "Merged data saved to no_duplicates_www.ocsentinel.csv\n",
      "Merged data saved to no_duplicates_montclairdispatch.csv\n",
      "Merged data saved to no_duplicates_987thecoast.csv\n",
      "Merged data saved to no_duplicates_www.spartaindependent.csv\n",
      "Merged data saved to no_duplicates_mcccvoice.csv\n",
      "Merged data saved to no_duplicates_www.courierpostonline.csv\n",
      "Merged data saved to no_duplicates_thecore.csv\n",
      "Merged data saved to no_duplicates_downbeachbuzz.csv\n",
      "Merged data saved to no_duplicates_www.ahherald.csv\n",
      "Merged data saved to no_duplicates_nyc.csv\n",
      "Merged data saved to no_duplicates_ntd.csv\n",
      "Merged data saved to no_duplicates_www.irishcentral.csv\n",
      "Merged data saved to no_duplicates_wpst.csv\n",
      "Merged data saved to no_duplicates_943thepoint.csv\n",
      "Merged data saved to no_duplicates_southjerseyobserver.csv\n",
      "Merged data saved to no_duplicates_wqxr.csv\n",
      "Merged data saved to no_duplicates_unionnewsdaily.csv\n",
      "Merged data saved to no_duplicates_www.westmilfordmessenger.csv\n",
      "Merged data saved to no_duplicates_essexnewsdaily.csv\n",
      "Merged data saved to no_duplicates_wsus1023.iheart.csv\n",
      "Merged data saved to no_duplicates_princetoninfo.csv\n",
      "Merged data saved to no_duplicates_tapinto.csv\n",
      "Merged data saved to no_duplicates_gujaratdarpan.csv\n",
      "Merged data saved to no_duplicates_newjersey.news12.csv\n",
      "Merged data saved to no_duplicates_www.dailyprincetonian.csv\n",
      "Merged data saved to no_duplicates_www.theobserver.csv\n",
      "Merged data saved to no_duplicates_southjerseybiz.csv\n",
      "Merged data saved to no_duplicates_countywatchers.wordpress.csv\n",
      "Merging complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(folder_path, raw_df):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            csv_df = pd.read_csv(file_path)\n",
    "            \n",
    "            if 'news_url' in raw_df.columns:\n",
    "                merged_df = pd.merge(csv_df, raw_df, how='inner', on='news_url')\n",
    "                \n",
    "                merged_df.to_csv(file_path, index=False)\n",
    "                \n",
    "                print(f\"Merged data saved to {file_name}\")\n",
    "            else:\n",
    "                print(\"Error: 'news_url' column not found in the raw DataFrame.\")\n",
    "\n",
    "    print(\"Merging complete.\")\n",
    "\n",
    "folder_path = '/Users/gayathri/Documents/After_Merge_Data'\n",
    "raw_df = pd.read_csv('/Users/gayathri/Documents/nj-local-news-analysis/all_domain_text.csv')  # Assuming raw data is loaded from a CSV file\n",
    "merge_csv_files(folder_path, raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d9a1b29-41af-4779-bee0-5619b0c0fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/xf93n76s47j1cw7f6v661b040000gn/T/ipykernel_19670/1170575625.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging complete. Merged file saved as 'After_Merge_Data.csv'.\n"
     ]
    }
   ],
   "source": [
    "###This merge is from the analysed_data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = '/Users/gayathri/Documents/After_Merge_Data'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each CSV file and merge its data into the main DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('After_Merge_Data.csv', index=False)\n",
    "\n",
    "print(\"Merging complete. Merged file saved as 'After_Merge_Data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a81446a-d15b-44d6-9679-a3bd8f8ff7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = '/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/No_Duplicates_Data'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each CSV file and merge its data into the main DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('No_Duplicates_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20c6e456-ed0f-4ba1-ba3d-56d945b3377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_data = pd.read_csv('/Users/gayathri/Library/CloudStorage/Box-Box/Local News Data/all_domain_data/merged_log.csv')\n",
    "no_duplicates_data = pd.read_csv('/Users/gayathri/Documents/nj-local-news-analysis/No_Duplicates_Data.csv')\n",
    "after_merge_data = pd.read_csv('/Users/gayathri/Documents/nj-local-news-analysis/After_Merge_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "372b3947-826a-499b-9703-c5c39ec5efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28473, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b4d2e43-992a-4173-96ac-34f2b6625f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28473, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_duplicates_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f74c392a-1209-46b6-be8d-0520386796d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28487, 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_merge_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afa2e5-756f-4d94-81e8-5681239717ad",
   "metadata": {},
   "source": [
    "##let's find the rows that are extra in after_merge_data but not in no_duplicates_data => this is very surprising, let'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b02c36e8-0fbe-4264-980b-dfd74ad3f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_non_common_rows(file1, file2, output_file):\n",
    "    # Read CSV files into DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    \n",
    "    # Extract 'news_url' columns from both DataFrames\n",
    "    news_url_df1 = df1['news_url']\n",
    "    news_url_df2 = df2['news_url']\n",
    "    \n",
    "    # Find 'news_url' values that are not common between the two DataFrames\n",
    "    non_common_urls = pd.concat([news_url_df1[~news_url_df1.isin(news_url_df2)], news_url_df2[~news_url_df2.isin(news_url_df1)]])\n",
    "    \n",
    "    # Filter rows based on non-common 'news_url' values\n",
    "    non_common_rows = df1[df1['news_url'].isin(non_common_urls)]\n",
    "    \n",
    "    # Write the non-common rows to a new CSV file\n",
    "    non_common_rows.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "file1 = '/Users/gayathri/Documents/nj-local-news-analysis/No_Duplicates_Data.csv'\n",
    "file2 = '/Users/gayathri/Documents/nj-local-news-analysis/After_Merge_Data.csv'\n",
    "output_file = 'non_common_rows.csv'\n",
    "filter_non_common_rows(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "546d74ea-73c5-455d-a1a6-5bcbdb65a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.read_csv('/Users/gayathri/Documents/nj-local-news-analysis/non_common_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf290acd-2648-42a2-bcfa-dc3ba148d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_url</th>\n",
       "      <th>outlet</th>\n",
       "      <th>outlet_latitude</th>\n",
       "      <th>outlet_longitude</th>\n",
       "      <th>gpe</th>\n",
       "      <th>gpe_latitude</th>\n",
       "      <th>gpe_longitude</th>\n",
       "      <th>gpe_county</th>\n",
       "      <th>gpe_occurrences</th>\n",
       "      <th>group_ID</th>\n",
       "      <th>gpe_new</th>\n",
       "      <th>gpe_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://rennamedia.com/publications/clark-mont...</td>\n",
       "      <td>rennamedia.com</td>\n",
       "      <td>40.680873</td>\n",
       "      <td>-74.431052</td>\n",
       "      <td>Oktoberfest</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oktoberfest</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://rennamedia.com/publications/berkeley-h...</td>\n",
       "      <td>rennamedia.com</td>\n",
       "      <td>40.680873</td>\n",
       "      <td>-74.431052</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>37.871523</td>\n",
       "      <td>-122.273042</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://rennamedia.com/publications/berkeley-h...</td>\n",
       "      <td>rennamedia.com</td>\n",
       "      <td>40.680873</td>\n",
       "      <td>-74.431052</td>\n",
       "      <td>Berkeley Heights’</td>\n",
       "      <td>40.680873</td>\n",
       "      <td>-74.431052</td>\n",
       "      <td>Union County</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Berkeley Heights’</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://987thecoast.com/election-day-2019-cover...</td>\n",
       "      <td>987thecoast.com</td>\n",
       "      <td>38.991780</td>\n",
       "      <td>-74.814889</td>\n",
       "      <td>Banning</td>\n",
       "      <td>33.925571</td>\n",
       "      <td>-116.876410</td>\n",
       "      <td>Riverside County</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Banning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://987thecoast.com/election-day-2019-cover...</td>\n",
       "      <td>987thecoast.com</td>\n",
       "      <td>38.991780</td>\n",
       "      <td>-74.814889</td>\n",
       "      <td>Cumberland</td>\n",
       "      <td>35.899473</td>\n",
       "      <td>-85.023346</td>\n",
       "      <td>Cumberland County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumberland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            news_url           outlet  \\\n",
       "0  https://rennamedia.com/publications/clark-mont...   rennamedia.com   \n",
       "1  https://rennamedia.com/publications/berkeley-h...   rennamedia.com   \n",
       "2  https://rennamedia.com/publications/berkeley-h...   rennamedia.com   \n",
       "3  http://987thecoast.com/election-day-2019-cover...  987thecoast.com   \n",
       "4  http://987thecoast.com/election-day-2019-cover...  987thecoast.com   \n",
       "\n",
       "   outlet_latitude  outlet_longitude                gpe  gpe_latitude  \\\n",
       "0        40.680873        -74.431052        Oktoberfest     37.090240   \n",
       "1        40.680873        -74.431052           Berkeley     37.871523   \n",
       "2        40.680873        -74.431052  Berkeley Heights’     40.680873   \n",
       "3        38.991780        -74.814889            Banning     33.925571   \n",
       "4        38.991780        -74.814889         Cumberland     35.899473   \n",
       "\n",
       "   gpe_longitude         gpe_county  gpe_occurrences  group_ID  \\\n",
       "0     -95.712891                NaN                1         1   \n",
       "1    -122.273042     Alameda County                8         3   \n",
       "2     -74.431052       Union County                1        11   \n",
       "3    -116.876410   Riverside County                1         0   \n",
       "4     -85.023346  Cumberland County                1         1   \n",
       "\n",
       "             gpe_new  gpe_sum  \n",
       "0        Oktoberfest        7  \n",
       "1           Berkeley        8  \n",
       "2  Berkeley Heights’        3  \n",
       "3            Banning        1  \n",
       "4         Cumberland        1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0982ab54-2339-469f-8b9c-c9c70085ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8a16b-501c-44d2-895c-47540bffa30a",
   "metadata": {},
   "source": [
    "#We see that there is no bart_info appended to these rows which is fine considering the length of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
